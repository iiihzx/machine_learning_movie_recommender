{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sunrise-bobby",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td class=\"sessionId\">9</td><td>None</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"/spark/erin/40512/jobs\">Link</a></td><td></td><td>erin</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df=spark.sql(\"select * from user_erin.rating\")\n",
    "(train, test) = df.randomSplit([0.8, 0.2],seed = 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-agent",
   "metadata": {},
   "source": [
    "## 机器学习：ALS模型的调参与预测\n",
    "- ALS算法是基于模型的推荐算法。其基本思想是对稀疏矩阵进行模型分解，评估出缺失项的值，以此来得到一个基本的训练模型。然后依照此模型可以针对新的用户和物品数据进行评估。ALS采用交替的最小二乘法来算出缺失项。\n",
    "- 运用TrainValidationSplit（TVS）来进行参数调优。TVS对于每个参数组合只进行一次评估，当训练数据集足够大时，开销较小，并且产生的结果可靠。TVS会创建单个 (training, test) pair。它使用trainRatio参数将数据集split成两部分。例如： trainRatio=0.8，TVS会生成一个训练集（80%）和一个测试集（20%）。TVS最后会使用Estimator、以及最好的ParamMap，对整个数据集进行拟合。\n",
    "- 运用param_grid方程来定义TVS检测的参数，在以下单元格，regParam有四个参数选择，所以最后一共有四种参数组合模型被测试。\n",
    "- 如果您的数据集较小，并想测试多种参数组合，可以在参数列表里加入希望测试的数值。\n",
    "- maxIter 设置的越大结果越精确，但是设置的越大也就意味着越耗时；一般建议10-20。\n",
    "- regParam:惩罚函数的因数，是ALS的正则化参数。如果设置很大就可以防止过拟合问题，如果设置很小，就不会有防止过拟合的功能了。\n",
    "- rank设置范围为10-100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lonely-logic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "als= ALS(userCol=\"user\",itemCol=\"movie\",ratingCol=\"rating\",nonnegative=True,implicitPrefs=False, coldStartStrategy=\"drop\",maxIter=10)\n",
    "als_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"rating\",metricName=\"rmse\")\n",
    "param_grid = ParamGridBuilder() \\\n",
    "            .addGrid(als.regParam, [ .01]) \\\n",
    "            .build()\n",
    "#, .05, .1, .15\n",
    "tvs = TrainValidationSplit(estimator=als,\n",
    "                           estimatorParamMaps=param_grid,\n",
    "                           evaluator=als_evaluator,\n",
    "                           trainRatio = 0.8)\n",
    "model=tvs.fit(train)\n",
    "model=model.bestModel\n",
    "als_prediction=model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "effective-printing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute error = 1.04900298892291"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(metricName=\"mae\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "\n",
    "mae = evaluator.evaluate(als_prediction)\n",
    "print(\"mean absolute error = \" + str(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-symbol",
   "metadata": {},
   "source": [
    "## 机器学习：预测储存与模型导出\n",
    "- 您可以通过hdfs路径以及存入模型的模型种类，将模型导出进行重复使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cultural-bouquet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "als_prediction.write.saveAsTable(\"user_erin.rating_al\", format=\"orc\", mode=\"overwrite\")\n",
    "model.write().overwrite().save(\"hdfs:///user/erin/data/mllib/alsmodel\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "important-concentrate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-michael",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

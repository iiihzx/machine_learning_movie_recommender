{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "novel-triangle",
   "metadata": {},
   "source": [
    "## 数据采集：\n",
    "- 以下这个单元格的功能是将您上传的csv文件读入到pyspark程序里，并将其的格式转换为pyspark dataframe。\n",
    "- 您可以通过改变spark.read.csv()中的路径来读入您本人上传的数据集。\n",
    "- data.show()是将dataframe的内容展示出来的方程。展示出来的数据集默认是前20行，您可以通过在show（）中填写数字，来改变展示的行数。例如show（1），会展示数据集中的第一行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ambient-phenomenon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td class=\"sessionId\">5</td><td>None</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"/spark/erin/40337/jobs\">Link</a></td><td></td><td>erin</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|    110|   1.0|1425941529|\n",
      "+------+-------+------+----------+\n",
      "only showing top 1 row\n",
      "\n",
      "+---+---------+\n",
      "| id|    title|\n",
      "+---+---------+\n",
      "|862|Toy Story|\n",
      "+---+---------+\n",
      "only showing top 1 row"
     ]
    }
   ],
   "source": [
    "data=spark.read.csv('hdfs://default/user/erin/ratings_demo.csv',header=True)\n",
    "name=spark.read.csv('hdfs://default/user/erin/movies_metadata.csv', header=True)\n",
    "name=name.select(\"id\",\"title\")\n",
    "data.show(1)\n",
    "name.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "violent-renewal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success"
     ]
    }
   ],
   "source": [
    "for col in data.columns:\n",
    "    data = data.withColumnRenamed(col, col.lower())\n",
    "for col in name.columns:\n",
    "    name = name.withColumnRenamed(col, col.lower())\n",
    "print('success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "distinguished-marina",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userid|movieid|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|    110|   1.0|1425941529|\n",
      "|     1|   2959|   4.0|1425941601|\n",
      "|     1|  81834|   5.0|1425942133|\n",
      "|     1|  98809|   0.5|1425942640|\n",
      "|     1| 112552|   5.0|1425941336|\n",
      "|     2|     58|   3.0| 867039325|\n",
      "|     4|   1221|   5.0|1042667903|\n",
      "|     4|   1732|   3.0|1042674761|\n",
      "|     4|   2541|   3.0|1042668576|\n",
      "|     4|   3160|   4.0|1042672335|\n",
      "+------+-------+------+----------+\n",
      "only showing top 10 rows"
     ]
    }
   ],
   "source": [
    "data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "burning-enemy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+-----------------+\n",
      "|userid|movieid|rating| timestamp|            title|\n",
      "+------+-------+------+----------+-----------------+\n",
      "|     1|    110|   1.0|1425941529|Three Colors: Red|\n",
      "+------+-------+------+----------+-----------------+\n",
      "only showing top 1 row"
     ]
    }
   ],
   "source": [
    "data = data.join(name, data.movieid == name.id)\n",
    "data=data.select(\"userid\",\"movieid\",\"rating\",\"timestamp\",\"title\")\n",
    "data.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-water",
   "metadata": {},
   "source": [
    "## 数据处理：1.处理重复数据\n",
    "- 整行去重：data.distinct()这个方程可以对于完全相同的行进行去重。\n",
    "- 对于某一列或者多列相同情况，进行去重： 您可以在dropDuplicates（）这个方程中，在队列中，填入您需要筛选的相同情况。例如以下单元格筛选了两个条件的情况，在产品，用户都一样的情况下，删除掉重复行（[\"User\", \"Movie\"]）。\n",
    "- data.count()方程会打印出这个列表的行数，以便于您了解去重之后的数据集行数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "protective-criticism",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1134791"
     ]
    }
   ],
   "source": [
    "data=data.distinct()\n",
    "data = data.dropDuplicates(subset=[c for c in data.columns if c in [\"userid\",\"movieid\"]])\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-reform",
   "metadata": {},
   "source": [
    "## 数据处理：2.处理空缺数据\n",
    "- 运用agg方程算出每列空缺的数据比\n",
    "- 若某列的空缺比重过大，可以将该列从数据中删除。因为data的空缺比均很小(为0.0，表示没有空缺)，所以使用df_miss来展示如何进行某列的删除，但后续处理中并不使用df_miss。这里删除的列为“Time”，您可以将“Time”换成您需要删除的列名。\n",
    "- 删除掉结果项空缺的数据（data.na.drop(subset=['Score'])），这个数据分析主要是对于“Score”项，当Score缺失，该行对于后续分析则没有帮助。\n",
    "- 删除掉空缺项过多的行。您可以通过利用thresh参数，为每一行缺失数据的数量指定一个阈值，从而限定要删除的行。以下我们选择的阈值为2，则删除掉空缺项等于或大约2的行。您可以改变thresh对应的值来改变阈值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "attempted-wisconsin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------+--------------+-----------------+--------------------+\n",
      "|userid_missing|movieid_missing|rating_missing|timestamp_missing|       title_missing|\n",
      "+--------------+---------------+--------------+-----------------+--------------------+\n",
      "|           0.0|            0.0|           0.0|              0.0|0.009246636605330871|\n",
      "+--------------+---------------+--------------+-----------------+--------------------+"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as f\n",
    "data.agg(*[(1-(f.count(c) /f.count('*'))).alias(c+'_missing') for c in data.columns]).show()\n",
    "data=data.na.drop(subset=['rating'])\n",
    "data=data.dropna(thresh=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-disability",
   "metadata": {},
   "source": [
    "## 数据处理：3.对列进行重命名\n",
    "- 有些数据集自带的列名代表的含义不太清晰，或者拼写起来比较复杂，您可以对列名进行自定义\n",
    "- 您可以使用withColumnRenamed（）这个方程，在括号中填入原列名（比如‘User’），在下一位填入新列名（比如‘user’），然后原列名就会被新列名替换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "removable-height",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[user: string, movie: string, rating: string, timestamp: string, title: string]"
     ]
    }
   ],
   "source": [
    "data=data.withColumnRenamed('userid', 'user')\n",
    "data=data.withColumnRenamed('movieid', 'movie')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-pension",
   "metadata": {},
   "source": [
    "## 数据处理：4.将某列数据的类别进行转化\n",
    "- 当您直接用spark的read_csv导入数据时，生成的dataframe往往会默认每列的类别为string，然而string类别会让您接下来的数据分析以及训练的步骤报错。\n",
    "- 以下这个单元格将四列的数据种类进行了改变。您可以通过在withColumn这个方程来进行改变，在括号中填入您想要改变的列名，以及想改变成的种类形式。形式：（“列名”,dataframe[\"列名\"].cast('type')）\n",
    "- 以下为一些您可能需要使用的类别：</br>binary;boolean;int;string;float;timestamp;date;float</br>您可以根据数据种类将以上类别替换到'type'里。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "public-launch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data= data.withColumn(\"user\",data['user'].cast('int'))\n",
    "data= data.withColumn(\"rating\",data['rating'].cast('int'))\n",
    "data= data.withColumn(\"movie\",data[\"movie\"].cast('int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-wedding",
   "metadata": {},
   "source": [
    "## 数据处理：5.将包含不符合打分要求的结果项的行删除\n",
    "- 首先将数据集根据rating项的不同值进行分类，并把每类的数量列出，再筛选出合理的rating值，并删掉rating值在合理范围外的行。\n",
    "- 您可以通过修改groupBy（)中的列名来选择依照分类的结果项。\n",
    "- 对于筛选结果项的范围，您可以将合理的结果值填入filter（）方程中，例如（data.rating==0），并且将这些等式用‘|’隔开，表示并列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "precious-rates",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|rating|count |\n",
      "+------+------+\n",
      "|4     |391970|\n",
      "|3     |366406|\n",
      "|5     |178675|\n",
      "|2     |128131|\n",
      "|1     |54642 |\n",
      "|0     |14967 |\n",
      "+------+------+"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "data.groupBy(\"rating\").count().orderBy(col(\"count\").desc()).show(truncate=False)\n",
    "data=data.filter(( data.rating== 0)|( data.rating== 1)|(data.rating == 2) | (data.rating == 3) | (data.rating == 4)|(data.rating == 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "progressive-script",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.write.format(\"hive\").mode(\"overwrite\").saveAsTable(\"user_erin.rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "accredited-citizen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-registrar",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
